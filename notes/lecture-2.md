
# Lecture 2 note

Sementic Gap : 픽셀 값의 숫자 집합과 실제 그 이미지에 붙인 레이블의 차이

## Image Classification Challenges

Viewpoint Variation : 대상이 가만이 있어도 카메라를 조금만 움직이면 픽셀 값은 크게 달라진다    
Illumination : 대상의 채광이 다름    
Deformation : 대상이 조금 변형이 일어남    
Occlusion : 대상이 조금 가려짐    
Background Clutter : 대상과 배경이 거의 비슷 하게 생김    
Intraclass Variation : 하나의 대상 클래스에 대해서도 다양성이 존재    

이미지를 분류하는 분명한 알고리즘이 존재하지 않는다

## Corner, Edge를 이용한 방법

처음에는 이미지에서 Corner와 Edge를 구한 다음에 이 값을 가지고 명시적인 규칙을 만들어서 분류를 시도해보았다     
문제 1 : Robust 하지 않다.    
문제 2 : 다른 객체를 인식해야 한다면 그에 맞는 것을 또 만들어야 한다.    
=> 확장성이 없다.

## Data-Driven Approach

직접 규칙을 만들지 않고 스스로 이미지를 보고 규칙을 학습하게 한다.    
그래서 이미지 분류를 하려면 train 함수와 predict 함수 2개가 필요해짐.

## Nearest Neighbor

train 단계에서 아무 것도 하지 않고 학습 데이터를 단순히 기억하기만 한다.    
predict 단계에서 학습 데이터 중에 가장 비슷한 사진을 찾는다.

그럼 비슷하다는 것을 어떻게 알까?    
L1 Distance (Manhattan Distance) : 각 픽셀 들의 차이를 모두 더한다.

N개의 테스트 케이스가 있으면 예측하는데 얼마나 오래 걸리나?    
Train O(1), Test O(N)    
근데 우리는 train에서는 조금 느려도 test에서는 빠른 것을 원한다.

문제 : 가장 가까운 값을 찾기 때문에 영역의 한 가운데에 noise나 거짓 값이 있으면 민감하게 반응하여 다른 결과를 내버린다.    
해결 => kNN

Q. Decision Boundary에서 흰 부분은 어떻게 측정하나.    
A. 니 맘이다.

이미지 분류에서 kNN은 별로 좋지 않다.    
kNN에서 L1 Distance보다 L2 Distance (Euclidean Distance)가 더 낫다.

L1 : 어떤 좌표계냐에 따라 많은 영향을 받는다. Feature 벡터의 요소들의 개별적인 의미를 가지고 있다면 이게 더 좋다. (키, 몸무게 등)    
L2 : 좌표계에 영향을 받지 않는다. 벡터 요소들과의 차이를 잘 모르겠다면 이게 좋다.    
다양한 거리 측정 방법을 이용하면 문장에서도 사용할 수 있다.

## Hyperparameter

Train 할 때 학습하는 것이 아니라 학습 전 사전에 선택해야 하는 값들    
어떤 문제를 해결 하려고 하느냐에 따라 매우 달라지고 대부분 다양한 값을 시도해서 나온 좋은 값을 쓴다.

시도 1 : 모든 데이터를 학습한 다음에 가장 성능이 좋은 것을 고른다.    
=> 그럼 항상 K = 1인 kNN이 가장 성능이 좋게 나온다.

시도 2 : 데이터중 일부를 쪼개서 테스트 데이터로 쓴 뒤, 테스트 성능이 가장 좋은 것을 쓴다.    
=> 새로운 데이터에 대해 잘 작동할지 모른다. 이렇게 하면 그저 테스트 데이터에서만 잘 작동하는 것을 Hyperparameter를 선택할 수도 있다.

시도 3 : 데이터를 train, validation, test로 나누어서 다양한 하이퍼파라미터로 학습한 모델을 validation set으로 검증한다. 테스트 셋은 한 번만 수행

Cross Validation : 데이터 양이 적을 때 사용, 딥러닝에서는 잘 안 쓴다. train 한 번 한 번이 오래 걸리기 때문. 자세한 설명은 생략.

Q. Training set과 Validation set의 구체적인 차이?    
A. Training set은 학습할 때 label을 볼 수 있지만 Validation set은 성능 체크할 때 말고는 볼 수 없다.

Q. 테스트 셋이 한 번도 보지 못한 데이터를 대표할 수 있는가?
A. 통계학 적인 가정에서 나온 발상이다. 여러분의 모든 데이터는 모두 독립적이며 동일한 분포를 따른다고 생각한다. 실제로 그렇지 않은 경우가 많다.
데이터를 순차적으로 모으고 있을 때 먼저 얻은 것을 train으로 쓰고 나중에 얻은 것을 test로 쓰면 문제가 생길 수 있다. 무작위로 섞어서 하는 것이 짱이다.

kNN의 문제 1 : 너무 느리다.    
kNN의 문제 2 : L1, L2 거리가 이미지간의 거리를 측정하는데 적절하지 않다. L2 거리가 이미지들 간의 지각적 유사도를 측정하는 데 적합하지 않다.    
kNN의 문제 3 : 잘 작동하려면 공간을 조밀하게 차지하고 있는 데이터 셋이 있어야 하는데 차원이 증가 할 수록 필요한 데이터의 양이 기하급수적으로 증가한다.

Q. 이미지가 모두 같은 사람인데 distance가 같으면 좋은게 아닌가?    
A. 서로 다른 클래스의 이미지를 변형해서 같은 distance로 만들 수 있는 반례도 있다.

## Linear Classification

NN을 구현할 때 Linear Classifier를 레고 블럭 처럼 쌓아서 만든다.    
Linear Classifier는 Parametric model의 가장 단순한 형태.    
Parametric model은 두 가지 요소가 있다. 입력 값과 가중치이다.    
Parametric approach에서는 학습 데이터의 정보를 요약해서 가중치에 모아준다.    
입력 값과 가중치를 합치는 가장 쉬운 방법이 둘을 곱하는 것인데 이것이 Linear Classifier.    
계산해 보면 W의 차원이 10x3072가 되어야 한다.    
Bias는 입력 값과 무관하게 특정 클래스에 우선권을 부여한다. 데이터 셋이 불균형한 상황에서는 이런 우선권이 많을 수 있다.    

Linear classification은 템플릿 매칭과 거의 유사하다.    
W의 각 행을 각 이미지에 대한 템플릿으로 보고 그 행 벡터와 이미지 열 벡터를 dot product 하는데 이 것이 탬플릿과의 유사도 측정임을 알 수 있다.    
따라서 W의 한 행을 이미지로 시각화 시켜보면 Linear Classifier가 어떤 일을 하는지 알 수 있다.    
Linear classifier의 문제는 각 클래스에 대해서 단 하나의 템플릿만을 학습하다는 것이다. 그래서 다양한 특징을 평균낸 것이 템플릿이기 때문에 조금 이상하게 생겼다.    

각 이미지를 고차원 상의 한 점이라고 생각함녀 Linear Classifier는 선형 경계를 그어주는 역할을 한다.    
여기서 생기는 문제가 다양한 데이터 셋을 선 하나로만 구분할 수가 없는 경우가 많다는 것이다.